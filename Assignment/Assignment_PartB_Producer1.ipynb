{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publishing records..\n",
      "Message published successfully. Data: -37.465,148.153,11,43.5,13.1,21, 0.24G,11/06/2020-15:12:27\n",
      "Message published successfully. Data: -37.238,141.145,8,41.6,8.3,15.9, 0.24G,11/06/2020-15:12:37\n",
      "Message published successfully. Data: -37.635,149.303,24,53.4,9.9,15.9, 0.00I,11/06/2020-15:12:47\n",
      "Message published successfully. Data: -36.3114,142.7605,28,56.7,9.3,16.9, 0.00I,11/06/2020-15:12:57\n",
      "Message published successfully. Data: -37.978,145.623,21,59.5,12.4,21, 0.00I,11/06/2020-15:13:07\n",
      "Message published successfully. Data: -36.5871,144.961,13,43.6,9,15, 0.00I,11/06/2020-15:13:17\n",
      "Message published successfully. Data: -36.9817,143.5051,14,44,14.4,23.9, 0.16G,11/06/2020-15:13:27\n",
      "Message published successfully. Data: -37.758,148.721,9,41.2,9.8,15.9, 0.00I,11/06/2020-15:13:37\n",
      "Message published successfully. Data: -36.059,143.7718,18,53.8,6.4,11.1, 0.00I,11/06/2020-15:13:47\n",
      "Message published successfully. Data: -37.227,141.146,10,44.9,5.5,8.9, 0.00G,11/06/2020-15:13:57\n"
     ]
    }
   ],
   "source": [
    "# import statements\n",
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka import KafkaProducer\n",
    "import random\n",
    "import datetime as dt\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "from datetime import timedelta  \n",
    "\n",
    "#SEND MESSAGE TO KAFKA BROKER\n",
    "\n",
    "def publish_message(producer_instance, topic_name, key, value):\n",
    "    try:\n",
    "        key_bytes = bytes(key, encoding='utf-8')\n",
    "        value_bytes = bytes(value, encoding='utf-8')\n",
    "        producer_instance.send(topic_name, key=key_bytes, value=value_bytes)\n",
    "        producer_instance.flush()\n",
    "        print('Message published successfully. Data: ' + str(value))\n",
    "    except Exception as ex:\n",
    "        print('Exception in publishing message.')\n",
    "        print(str(ex))\n",
    "\n",
    "        \n",
    "# CONNECT TO KAFKA BROKER\n",
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    try:\n",
    "        _producer = KafkaProducer(bootstrap_servers=['localhost:9092'],\n",
    "                                  api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka.')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _producer\n",
    "    \n",
    "\n",
    "#READ STREAMING DATA\n",
    "def read_data(filename):\n",
    "    \n",
    "    data = []\n",
    "    with open(filename) as csvfile:\n",
    "         i = 0\n",
    "         for row in csvfile:\n",
    "            if(i == 0):\n",
    "                i+=1\n",
    "                continue\n",
    "            row = row.strip()\n",
    "            data.append(row)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "#GET RANDOM DATA\n",
    "def get_random(data):\n",
    "    return random.choice(data)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "   \n",
    "    #TOPIC IS CLIMATE\n",
    "    #CREATE DATA TO SEND\n",
    "    #ADD EVENT DATETIME\n",
    "    #SEND KEY\n",
    "    # SEND DATA EVERY 10 10 SECONDS\n",
    "    \n",
    "    topic = 'climate'\n",
    "    \n",
    "    print('Publishing records..')\n",
    "    producer = connect_kafka_producer()\n",
    "    climate_data = read_data(\"climate_streaming.csv\")\n",
    "    \n",
    "    \n",
    "    for e in range(10):\n",
    "        #data = str(dt.datetime.now().strftime(\"%X\")) + ', ' + str(random.randrange(0,100))\n",
    "        \n",
    "        data_to_send = get_random(climate_data)\n",
    "        data_to_send = data_to_send + \",\" + dt.datetime.now().strftime(\"%d/%m/%Y-%H:%M:%S\")\n",
    "        publish_message(producer, topic, 'producer_1', data_to_send)\n",
    "        sleep(10)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command to list topics in kafka server\n",
    "\n",
    "sudo bin/kafka-topics.sh --list --zookeeper localhost:2181\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
